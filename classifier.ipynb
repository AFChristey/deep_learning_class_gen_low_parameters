{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "(1)\n",
    "Model architecture adapted from:\n",
    "Yerlan Idelbayev. Proper ResNet Implementation for CIFAR10/CIFAR100 in Py-\n",
    "Torch. https : / / github . com / akamaster / pytorch _ resnet _ cifar10. Accessed:\n",
    "26-01-2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as disp\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to make getting another batch of data easier\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "            \n",
    "  \n",
    "# Data augmentation transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Class names for images\n",
    "class_names = ['apple','aquarium_fish','baby','bear','beaver','bed','bee','beetle','bicycle','bottle','bowl','boy','bridge','bus','butterfly','camel','can','castle','caterpillar','cattle','chair','chimpanzee','clock','cloud','cockroach','couch','crab','crocodile','cup','dinosaur','dolphin','elephant','flatfish','forest','fox','girl','hamster','house','kangaroo','computer_keyboard','lamp','lawn_mower','leopard','lion','lizard','lobster','man','maple_tree','motorcycle','mountain','mouse','mushroom','oak_tree','orange','orchid','otter','palm_tree','pear','pickup_truck','pine_tree','plain','plate','poppy','porcupine','possum','rabbit','raccoon','ray','road','rocket','rose','sea','seal','shark','shrew','skunk','skyscraper','snail','snake','spider','squirrel','streetcar','sunflower','sweet_pepper','table','tank','telephone','television','tiger','tractor','train','trout','tulip','turtle','wardrobe','whale','willow_tree','wolf','woman','worm',]\n",
    "\n",
    "# Updated data loaders with data augmentation\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.CIFAR100('data', train=True, download=True, transform=transform_train),\n",
    "    batch_size=320, shuffle=True, drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.CIFAR100('data', train=False, download=True, transform=transform_test),\n",
    "    batch_size=320, shuffle=False, drop_last=True)\n",
    "\n",
    "train_iterator = iter(cycle(train_loader))\n",
    "test_iterator = iter(cycle(test_loader))\n",
    "\n",
    "print(f'> Size of training dataset {len(train_loader.dataset)}')\n",
    "print(f'> Size of test dataset {len(test_loader.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some of the images\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img = test_loader.dataset[i+100][0].numpy().transpose(1, 2, 0)\n",
    "    plt.imshow(img*0.5+0.5)\n",
    "    plt.xlabel(class_names[test_loader.dataset[i+100][1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet CNN model.\n",
    "# Model has been inspired from (https://github.com/akamaster/pytorch_resnet_cifar10) (see top for references)\n",
    "\n",
    "# Basic building block for ResNet model.\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "# #         Added dropout - does not improve\n",
    "#         self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "              nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "              nn.BatchNorm2d(self.expansion*planes)\n",
    "          )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = F.elu(self.bn1(self.conv1(x)))\n",
    "        out = F.elu(self.bn2(self.conv2(out)))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.elu(out)\n",
    "        return out\n",
    "\n",
    "# Defines the ResNet model.\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=100):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.in_planes = 8\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.layer1 = self._make_layer(block, 12, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 19, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 32, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(64*block.expansion, num_classes)\n",
    "        \n",
    "        # Adjusted convolution layer for input x\n",
    "        self.conv1_adjusted = nn.Conv2d(3, 32, kernel_size=5, stride=4, padding=1, bias=False)\n",
    "        self.bn1_adjusted = nn.BatchNorm2d(32)\n",
    "        \n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.elu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        \n",
    "#       Add input (x) to out\n",
    "        x_adjusted = F.elu(self.bn1_adjusted(self.conv1_adjusted(x)))\n",
    "        out += x_adjusted\n",
    "        \n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "# Contains 2 layer 1 BasicBlocks, 2 layer 2 BasicBlocks and 1 layer 3 + 4 BasicBlock.\n",
    "N = Classifier(BasicBlock, [2,2,1,1]).to(device)\n",
    "# Wraps model with DataParallel to enable parallel processing across multiple GPUs.\n",
    "N = torch.nn.DataParallel(N)\n",
    "# Enables benchmark mode\n",
    "# cudnn.benchmark = True\n",
    "\n",
    "\n",
    "# print the number of parameters\n",
    "print(f'> Number of parameters {len(torch.nn.utils.parameters_to_vector(N.parameters()))}')\n",
    "\n",
    "if len(torch.nn.utils.parameters_to_vector(N.parameters())) > 100000:\n",
    "    print(\"> Warning: you have gone over your parameter budget and will have a grade penalty!\")\n",
    "\n",
    "# initialise the optimiser\n",
    "optimiser = torch.optim.Adam(N.parameters(), lr=0.01)\n",
    "\n",
    "plot_data = []\n",
    "steps = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grad_clip = 0.1\n",
    "\n",
    "# Scheduler to decrease learning rate every 1000 steps\n",
    "scheduler = StepLR(optimiser, step_size=1000, gamma=0.95)\n",
    "\n",
    "lr_arr = np.zeros(0)\n",
    "steps_arr = np.zeros(0)\n",
    "\n",
    "# keep within our optimisation step budget\n",
    "while (steps < 10000):\n",
    "\n",
    "    # arrays for metrics\n",
    "    train_loss_arr = np.zeros(0)\n",
    "    train_acc_arr = np.zeros(0)\n",
    "    test_acc_arr = np.zeros(0)\n",
    "    \n",
    "\n",
    "    # iterate through some of the train dateset\n",
    "    for i in range(1000):\n",
    "        x,t = next(train_iterator)\n",
    "        x,t = x.to(device), t.to(device)\n",
    "#       Zero the optimizer gradients\n",
    "        optimiser.zero_grad()\n",
    "#       Make predictions on input data\n",
    "        p = N(x)\n",
    "        pred = p.argmax(dim=1, keepdim=True)\n",
    "#       Compare predictions to target labels\n",
    "        loss = torch.nn.functional.cross_entropy(p, t)\n",
    "        \n",
    "#       Computes the gradfient of the loss with respect to model parameters using backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "#       Clip gradient to prevent them from becoming too large\n",
    "        if grad_clip:\n",
    "            nn.utils.clip_grad_value_(N.parameters(), grad_clip)\n",
    "        \n",
    "#       Update model parameters\n",
    "        optimiser.step()\n",
    "        steps += 1\n",
    "        \n",
    "        # Record the current learning rate and step\n",
    "        current_lr = optimiser.param_groups[0]['lr']\n",
    "        lr_arr = np.append(lr_arr, current_lr)\n",
    "        steps_arr = np.append(steps_arr, steps)\n",
    "        \n",
    "#       Adjust the learning rate based on schedule\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss_arr = np.append(train_loss_arr, loss.cpu().data)\n",
    "        train_acc_arr = np.append(train_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())\n",
    "\n",
    "    # iterate over the entire test dataset\n",
    "    for m,l in test_loader:\n",
    "        m,l = m.to(device), l.to(device)\n",
    "        p_test = N(m)\n",
    "        loss = torch.nn.functional.cross_entropy(p_test, l)\n",
    "        pred = p_test.argmax(dim=1, keepdim=True)\n",
    "        test_acc_arr = np.append(test_acc_arr, pred.data.eq(l.view_as(pred)).float().mean().item())\n",
    "\n",
    "    # print your loss and accuracy data\n",
    "    print('steps: {:.2f}, train loss: {:.3f}, train acc: {:.3f}±{:.3f}, test acc: {:.3f}±{:.3f}'.format(\n",
    "        steps, train_loss_arr.mean(),train_acc_arr.mean(),train_acc_arr.std(),test_acc_arr.mean(),test_acc_arr.std()))\n",
    "\n",
    "    # plot your accuracy graph\n",
    "    plot_data.append([steps, np.array(train_acc_arr).mean(), np.array(train_acc_arr).std(), np.array(test_acc_arr).mean(), np.array(test_acc_arr).std()])\n",
    "    reward_list = []\n",
    "    plt.plot([x[0] for x in plot_data], [x[1] for x in plot_data], '-', color='tab:grey', label=\"Train accuracy\")\n",
    "    plt.fill_between([x[0] for x in plot_data], [x[1]-x[2] for x in plot_data], [x[1]+x[2] for x in plot_data], alpha=0.2, color='tab:grey')\n",
    "    plt.plot([x[0] for x in plot_data], [x[3] for x in plot_data], '-', color='tab:purple', label=\"Test accuracy\")\n",
    "    plt.fill_between([x[0] for x in plot_data], [x[3]-x[4] for x in plot_data], [x[3]+x[4] for x in plot_data], alpha=0.2, color='tab:purple')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    disp.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RESULT VISUALISATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model.\n",
    "# model_path = 'Models/disciminative.pth'\n",
    "# torch.save(N, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model.\n",
    "# model_path = 'Models/disciminative.pth'\n",
    "# N = torch.load(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning rate over time\n",
    "plt.plot(steps_arr, lr_arr, label='Learning Rate')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for different superclasses\n",
    "\n",
    "different_class_names = ['bear', 'sea', 'man', 'motorcycle', 'apple', 'rose', 'oak_tree', 'table', 'bottle']\n",
    "\n",
    "\n",
    "# Get the indices corresponding to animal classes\n",
    "different_indices = [class_names.index(different) for different in different_class_names]\n",
    "\n",
    "\n",
    "# iterate over the entire test dataset\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for m, l in test_loader:\n",
    "    m, l = m.to(device), l.to(device)\n",
    "    p_test = N(m)\n",
    "    pred = p_test.argmax(dim=1, keepdim=True)\n",
    "    all_preds.extend(pred.cpu().numpy())\n",
    "    all_labels.extend(l.cpu().numpy())\n",
    "\n",
    "# Get the indices corresponding to animal superclasses\n",
    "# animal_indices = [4, 6, 8, 9, 11, 13, 16, 17]\n",
    "\n",
    "# Get the class labels for animal superclasses\n",
    "different_labels = [class_names[idx] for idx in different_indices]\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Filter the confusion matrix to include only animal indices\n",
    "different_conf_matrix = conf_matrix[different_indices][:, different_indices]\n",
    "\n",
    "# Plot the filtered confusion matrix with animal labels\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(different_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=different_labels, yticklabels=different_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(\"Different Superclass's Confusion Matrix\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for animal superclass\n",
    "\n",
    "animal_class_names = ['bear', 'beaver', 'bee', 'butterfly', 'cattle', 'chimpanzee',\n",
    "                      'cockroach', 'crocodile', 'dinosaur', 'dolphin', 'hamster',\n",
    "                      'kangaroo', 'leopard', 'otter', 'porcupine', 'possum',\n",
    "                      'rabbit', 'raccoon', 'ray', 'seal', 'shark', 'shrew', 'skunk', 'squirrel',\n",
    "                      'tiger', 'turtle', 'whale', 'wolf']\n",
    "\n",
    "# Get the indices corresponding to animal classes\n",
    "animal_indices = [class_names.index(animal) for animal in animal_class_names]\n",
    "\n",
    "\n",
    "# iterate over the entire test dataset\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for m, l in test_loader:\n",
    "    m, l = m.to(device), l.to(device)\n",
    "    p_test = N(m)\n",
    "    pred = p_test.argmax(dim=1, keepdim=True)\n",
    "    all_preds.extend(pred.cpu().numpy())\n",
    "    all_labels.extend(l.cpu().numpy())\n",
    "\n",
    "# Get the class labels for animal superclasses\n",
    "animal_labels = [class_names[idx] for idx in animal_indices]\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Filter the confusion matrix\n",
    "animal_conf_matrix = conf_matrix[animal_indices][:, animal_indices]\n",
    "\n",
    "# Plot the filtered confusion matrix\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(animal_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=animal_labels, yticklabels=animal_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Animal Superclass Confusion Matrix')\n",
    "\n",
    "# Save the plot as a JPEG image\n",
    "plt.savefig('animal_confusion_matrix.jpg', format='jpeg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for scenery superclass\n",
    "\n",
    "outdoor_class_names = ['plain', 'sea', 'cloud', 'forest', 'mountain']\n",
    "\n",
    "# Get the indices corresponding to scenery classes\n",
    "outdoor_indices = [class_names.index(outdoor) for outdoor in outdoor_class_names]\n",
    "\n",
    "\n",
    "# iterate over the entire test dataset\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for m, l in test_loader:\n",
    "    m, l = m.to(device), l.to(device)\n",
    "    p_test = N(m)\n",
    "    pred = p_test.argmax(dim=1, keepdim=True)\n",
    "    all_preds.extend(pred.cpu().numpy())\n",
    "    all_labels.extend(l.cpu().numpy())\n",
    "\n",
    "\n",
    "# Get the class labels\n",
    "outdoor_labels = [class_names[idx] for idx in outdoor_indices]\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Filter the confusion matrix\n",
    "outdoor_conf_matrix = conf_matrix[outdoor_indices][:, outdoor_indices]\n",
    "\n",
    "# Plot the filtered confusion matrix\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(outdoor_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=outdoor_labels, yticklabels=outdoor_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Outdoor Scenes Superclass Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for vehicle superclass\n",
    "\n",
    "vehicle_class_names = ['motorcycle', 'lawn_mower', 'rocket', 'streetcar', 'tank', 'tractor', 'bus', 'bicycle', 'train' ]\n",
    "\n",
    "# Get the indices corresponding to vehicle classes\n",
    "vehicle_indices = [class_names.index(vehicle) for vehicle in vehicle_class_names]\n",
    "\n",
    "\n",
    "# iterate over the entire test dataset\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for m, l in test_loader:\n",
    "    m, l = m.to(device), l.to(device)\n",
    "    p_test = N(m)\n",
    "    pred = p_test.argmax(dim=1, keepdim=True)\n",
    "    all_preds.extend(pred.cpu().numpy())\n",
    "    all_labels.extend(l.cpu().numpy())\n",
    "\n",
    "# Get the class labels\n",
    "vehicle_labels = [class_names[idx] for idx in vehicle_indices]\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Filter the confusion matrix\n",
    "vehicle_conf_matrix = conf_matrix[vehicle_indices][:, vehicle_indices]\n",
    "\n",
    "# Plot the filtered confusion matrix\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(vehicle_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=vehicle_labels, yticklabels=vehicle_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Vehicle Superclass Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for people superclass\n",
    "\n",
    "people_class_names = ['man', 'woman', 'boy', 'girl', 'baby']\n",
    "\n",
    "# Get the indices corresponding to people classes\n",
    "people_indices = [class_names.index(people) for people in people_class_names]\n",
    "\n",
    "\n",
    "# iterate over the entire test dataset\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for m, l in test_loader:\n",
    "    m, l = m.to(device), l.to(device)\n",
    "    p_test = N(m)\n",
    "    pred = p_test.argmax(dim=1, keepdim=True)\n",
    "    all_preds.extend(pred.cpu().numpy())\n",
    "    all_labels.extend(l.cpu().numpy())\n",
    "\n",
    "\n",
    "# Get the class labels\n",
    "people_labels = [class_names[idx] for idx in people_indices]\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Filter the confusion matrix\n",
    "people_conf_matrix = conf_matrix[people_indices][:, people_indices]\n",
    "\n",
    "# Plot the filtered confusion matrix\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(people_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=people_labels, yticklabels=people_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('People Superclass Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    plt.imshow(img*0.5+0.5)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    color = '#335599' if predicted_label == true_label else '#ee4433'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                  100*np.max(predictions_array),\n",
    "                                  class_names[true_label]),\n",
    "                                  color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(100), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('#ee4433')\n",
    "    thisplot[true_label].set_color('#335599')\n",
    "\n",
    "test_images, test_labels = next(test_iterator)\n",
    "test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "test_preds = torch.softmax(N(test_images), dim=1).data.cpu().numpy()\n",
    "num_rows = 8\n",
    "num_cols = 4\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, test_preds, test_labels.cpu().numpy(), test_images.cpu().numpy()) # Used .numpy() here\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i, test_preds, test_labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
